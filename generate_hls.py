#!/usr/bin/env python3
"""
Standalone HLS Code Generator for CHARM U50
Usage: python generate_hls.py --model models/bert.json --output design_space/acc_config.json
"""

import json
import os
import numpy as np
from pathlib import Path
import argparse
import time

# --- Configuration ---
PROJECT_ROOT = Path(__file__).parent.resolve()
KERNEL_DIR = PROJECT_ROOT / "kernels"
INCLUDE_DIR = PROJECT_ROOT / "include" / "kernel"
MODEL_DIR = PROJECT_ROOT / "models"
DESIGN_DIR = PROJECT_ROOT / "design_space"

class StandaloneHLSGenerator:
    def __init__(self):
        self.kernel_template = """// Auto-generated by CHARM
#include "utils.h"

#define TILE_M {tile_m}
#define TILE_N {tile_n}
#define TILE_K {tile_k}

extern "C" {{
void {kernel_name}(
    const float* A,  // HBM channel {hbm_start}
    const float* B,  // HBM channel {hbm_b_start} 
    float* C,
    int M, int K, int N
) {{
    #pragma HLS INTERFACE m_axi port=A offset=slave bundle=gmem{bundle_a}
    #pragma HLS INTERFACE m_axi port=B offset=slave bundle=gmem{bundle_b}
    #pragma HLS INTERFACE m_axi port=C offset=slave bundle=gmem{bundle_a}
    #pragma HLS INTERFACE s_axilite port=return
    {dataflow_pragma}

    float local_A[TILE_M][TILE_K];
    float local_B[TILE_K][TILE_N];
    #pragma HLS ARRAY_PARTITION variable=local_A cyclic factor={partition_factor} dim=1
    #pragma HLS ARRAY_PARTITION variable=local_B cyclic factor={partition_factor} dim=2
    #pragma HLS BIND_STORAGE variable=local_A type=ram_2p impl={mem_type}
    #pragma HLS BIND_STORAGE variable=local_B type=ram_2p impl={mem_type}

    {computation_code}
}}
}}"""
        
        self.large_computation_template = """
    for (int ti = 0; ti < M; ti += TILE_M) {{
        for (int tj = 0; tj < N; tj += TILE_N) {{
            #pragma HLS LOOP_FLATTEN
            read_block<float, TILE_M, TILE_K>(A + ti*K, local_A, TILE_M, TILE_K, K);
            read_block<float, TILE_K, TILE_N>(B + tj, local_B, TILE_K, TILE_N, N);

            for (int tk = 0; tk < K; tk += TILE_K) {{
                for (int i = 0; i < TILE_M; i++) {{
                    for (int j = 0; j < TILE_N; j++) {{
                        #pragma HLS PIPELINE II=1
                        float sum = 0;
                        for (int k = 0; k < TILE_K; k++) {{
                            sum += local_A[i][k] * local_B[k][j];
                        }}
                        C[(ti+i)*N + (tj+j)] = sum;
                    }}
                }}
            }}
        }}
    }}"""
        
        self.small_computation_template = """
    hls::stream<float> a_stream, b_stream;
    #pragma HLS STREAM variable=a_stream depth=32
    #pragma HLS STREAM variable=b_stream depth=32

    load_A: for(int i = 0; i < M*K; i++) {{
        #pragma HLS PIPELINE II=1
        a_stream.write(A[i]);
    }}

    load_B: for(int i = 0; i < K*N; i++) {{
        #pragma HLS PIPELINE II=1
        b_stream.write(B[i]);
    }}

    compute: for(int i = 0; i < M; i++) {{
        for(int j = 0; j < N; j++) {{
            #pragma HLS PIPELINE II=1
            float sum = 0;
            for(int k = 0; k < K; k++) {{
                sum += a_stream.read() * b_stream.read();
            }}
            C[i*N + j] = sum;
        }}
    }}"""

    def generate_utils_header(self):
        """Generate kernel utilities header"""
        utils_code = """#ifndef KERNEL_UTILS_H
#define KERNEL_UTILS_H

#include <ap_int.h>
#include <hls_stream.h>

template<typename T, int DIM1, int DIM2>
void read_block(const T* src, T dst[DIM1][DIM2], int rows, int cols, int ld) {
    #pragma HLS INLINE
    for (int i = 0; i < rows; i++) {
        #pragma HLS PIPELINE II=1
        for (int j = 0; j < cols; j++) {
            dst[i][j] = src[i*ld + j];
        }
    }
}

template<typename T, int DIM1, int DIM2>
void write_block(T* dst, const T src[DIM1][DIM2], int rows, int cols, int ld) {
    #pragma HLS INLINE
    for (int i = 0; i < rows; i++) {
        #pragma HLS PIPELINE II=1
        for (int j = 0; j < cols; j++) {
            dst[i*ld + j] = src[i][j];
        }
    }
}

#endif
"""
        INCLUDE_DIR.mkdir(parents=True, exist_ok=True)
        with open(INCLUDE_DIR / "utils.h", "w") as f:
            f.write(utils_code)
        print(f"✓ Generated {INCLUDE_DIR/'utils.h'}")

    def analyze_model(self, model_path):
        """Analyze model to determine accelerator types needed"""
        try:
            with open(model_path) as f:
                model = json.load(f)
            
            large_ops = 0
            small_ops = 0
            large_count = 0
            small_count = 0
            
            for layer in model.get("layers", []):
                if layer.get("type") == "mm":
                    ops = layer["M"] * layer["K"] * layer["N"]
                    if ops > 1e6:  # Large matrix
                        large_ops += ops
                        large_count += 1
                    else:  # Small matrix
                        small_ops += ops
                        small_count += 1
            
            print(f"Model analysis: {large_count} large layers, {small_count} small layers")
            print(f"Operations: {large_ops/1e9:.2f}G (large), {small_ops/1e9:.2f}G (small)")
            
            # Return both accelerators if both types exist
            return large_count > 0, small_count > 0
            
        except Exception as e:
            print(f"Error analyzing model: {e}")
            return True, True  # Default to both

    def generate_accelerator_config(self, model_path, output_path):
        """Generate optimized accelerator configuration based on model analysis"""
        DESIGN_DIR.mkdir(parents=True, exist_ok=True)
        
        needs_large, needs_small = self.analyze_model(model_path)
        accelerators = []
        
        if needs_large:
            accelerators.append({
                "type": "large",
                "tile": [256, 256, 128],
                "dsp": 2048,
                "hbm_channels": {"start": 0, "count": 16},
                "throughput": 2500.0,
                "efficiency": 0.85
            })
            print("✓ Added large matrix accelerator")
        
        if needs_small:
            accelerators.append({
                "type": "small", 
                "tile": [64, 64, 64],
                "dsp": 512,
                "hbm_channels": {"start": 16 if needs_large else 0, "count": 8},
                "throughput": 1071.2,
                "efficiency": 0.78
            })
            print("✓ Added small matrix accelerator")
        
        if not accelerators:
            print("⚠ No accelerators needed for this model")
            return None
        
        config = {
            "accelerators": accelerators,
            "model": Path(model_path).stem,
            "total_throughput": sum(acc["throughput"] for acc in accelerators)
        }
        
        with open(output_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"✓ Generated accelerator config: {output_path}")
        return config

    def generate_kernel(self, acc_config):
        """Generate HLS kernels from configuration"""
        if not acc_config or "accelerators" not in acc_config:
            print("⚠ No accelerators to generate")
            return
        
        KERNEL_DIR.mkdir(parents=True, exist_ok=True)
        
        for acc in acc_config["accelerators"]:
            is_large = acc["type"] == "large"
            
            template_vars = {
                "kernel_name": f"mm_{acc['type']}",
                "tile_m": acc["tile"][0],
                "tile_n": acc["tile"][1],
                "tile_k": acc["tile"][2],
                "hbm_start": acc["hbm_channels"]["start"],
                "hbm_b_start": acc["hbm_channels"]["start"] + acc["hbm_channels"]["count"] // 2,
                "bundle_a": 0 if is_large else 1,
                "bundle_b": 1 if is_large else 2,
                "partition_factor": min(32, acc["tile"][0]//4) if is_large else 1,
                "mem_type": "uram" if is_large else "bram",
                "dataflow_pragma": "#pragma HLS DATAFLOW" if is_large else "",
                "computation_code": self.large_computation_template if is_large else self.small_computation_template
            }
            
            kernel_code = self.kernel_template.format(**template_vars)
            kernel_path = KERNEL_DIR / f"mm_{acc['type']}.cpp"
            
            with open(kernel_path, 'w') as f:
                f.write(kernel_code)
            print(f"✓ Generated {kernel_path}")

def create_default_model():
    """Create default BERT model if not exists"""
    model_path = MODEL_DIR / "bert.json"
    if not model_path.exists():
        MODEL_DIR.mkdir(parents=True, exist_ok=True)
        default_model = {
            "name": "BERT",
            "layers": [
                {"type": "mm", "M": 3072, "K": 1024, "N": 1024},
                {"type": "mm", "M": 3072, "K": 4096, "N": 1024},
                {"type": "mm", "M": 3072, "K": 1024, "N": 4096},
                {"type": "mm", "M": 512, "K": 64, "N": 512},
                {"type": "mm", "M": 512, "K": 512, "N": 64}
            ]
        }
        with open(model_path, 'w') as f:
            json.dump(default_model, f, indent=2)
        print(f"✓ Created default model: {model_path}")
    return model_path

def main():
    parser = argparse.ArgumentParser(description="Standalone HLS Code Generator")
    parser.add_argument("--model", help="Input model JSON file", default="models/bert.json")
    parser.add_argument("--output", help="Output config file", default="design_space/acc_config.json")
    args = parser.parse_args()
    
    print("=== CHARM Standalone HLS Code Generator ===")
    
    # Create default model if needed
    model_path = create_default_model()
    
    # Use provided model path or default
    input_model = args.model if os.path.exists(args.model) else model_path
    
    # Initialize generator
    generator = StandaloneHLSGenerator()
    
    # Generate files
    generator.generate_utils_header()
    acc_config = generator.generate_accelerator_config(input_model, args.output)
    generator.generate_kernel(acc_config)
    
    print(f"\n=== Generation Complete ===")
    print("Generated files:")
    if acc_config:
        for acc in acc_config["accelerators"]:
            print(f"  - {KERNEL_DIR}/mm_{acc['type']}.cpp")
    print(f"  - {INCLUDE_DIR/'utils.h'}")
    print(f"  - {args.output}")

if __name__ == "__main__":
    main()